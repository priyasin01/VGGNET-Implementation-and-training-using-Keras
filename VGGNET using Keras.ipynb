{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/priyasin01/VGGNET-Implementation-and-training-using-Keras/blob/master/VGGNET%20using%20Keras.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "SRn-cNlvuqFx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rW4CB7x_vzmo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **IMPLEMENTING VGGNET WITH KERAS**\n"
      ]
    },
    {
      "metadata": {
        "id": "ugFquxmev_pe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "434db34f-3509-4b65-ab42-eae7df768421"
      },
      "cell_type": "code",
      "source": [
        "!pip install tflearn"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/ec/e9ce1b52e71f6dff3bd944f020cef7140779e783ab27512ea7c7275ddee5/tflearn-0.3.2.tar.gz (98kB)\n",
            "\u001b[K    100% |████████████████████████████████| 102kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.14.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.11.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->tflearn) (0.45.1)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Running setup.py bdist_wheel for tflearn ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/d0/f6/69/0ef3ee395aac2e5d15d89efd29a9a216f3c27767b43b72c006\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DE0uOiJIEx8x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "6988b07c-bfe3-4e1f-a8e1-3f313f365983"
      },
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, MaxPooling2D, Conv2D, Flatten, Dropout\n",
        "import numpy as np\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "#importing data\n",
        "import tflearn.datasets.oxflower17 as oxflower17\n",
        "x,y=oxflower17.load_data(one_hot=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Oxford 17 category Flower Dataset, Please wait...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100.0% 60276736 / 60270631\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "('Succesfully downloaded', '17flowers.tgz', 60270631, 'bytes.')\n",
            "File Extracted\n",
            "Starting to parse images...\n",
            "Parsing Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DjyakyPeE46u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1792
        },
        "outputId": "44cf417d-b576-4b65-a534-20bb12abee1a"
      },
      "cell_type": "code",
      "source": [
        "#creating VGGNET16 model\n",
        "model=Sequential()\n",
        "\n",
        "#1st and 2nd convolution layer\n",
        "model.add(Conv2D(filters=64, input_shape=(224,224,3), kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1, 1), padding='valid', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#maxpooling layer 1\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "\n",
        "#3rd and 4th convolutional layer\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#maxpooling layer 2\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "\n",
        "#5th,6th and 7th convolutional layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#maxpooling layer 3\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "\n",
        "#8th,9th and 10th convolutional layer\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#maxpooling layer 4\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid')) \n",
        "\n",
        "#11th, 12th and 13th convolutional layer \n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'))\n",
        "\n",
        "#maxpooling layer 5\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid')) \n",
        "\n",
        "#going for the fully connected layers\n",
        "model.add(Flatten())\n",
        "\n",
        "#1 Dense/Fully-connected layer\n",
        "model.add(Dense(4096, input_shape=(224,224,3)))\n",
        "model.add(Activation('relu'))\n",
        "#add dropout\n",
        "model.add(Dropout(0.4))\n",
        "#add batch normalization\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "#2 Dense/Fully-connected layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "#add dropout\n",
        "model.add(Dropout(0.5))\n",
        "#add batch normalization\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "\n",
        "#3 Dense/Fully-connected layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "#add dropout\n",
        "model.add(Dropout(0.5))\n",
        "#add batch normalization\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#output layer\n",
        "model.add(Dense(17))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x, y, batch_size=64, epochs=5, verbose=1, validation_split=0.2, shuffle='True' )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 222, 222, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 220, 220, 64)      36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 220, 220, 64)      256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 110, 110, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 108, 108, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 106, 106, 128)     147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 106, 106, 128)     512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 53, 53, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 51, 51, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 49, 49, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 47, 47, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 47, 47, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 23, 23, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 21, 21, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 19, 19, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 17, 17, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 17, 17, 512)       2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              2101248   \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 17)                69649     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 17)                0         \n",
            "=================================================================\n",
            "Total params: 50,501,201\n",
            "Trainable params: 50,474,705\n",
            "Non-trainable params: 26,496\n",
            "_________________________________________________________________\n",
            "Train on 1088 samples, validate on 272 samples\n",
            "Epoch 1/5\n",
            "1024/1088 [===========================>..] - ETA: 2s - loss: 3.7980 - acc: 0.0908"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1088/1088 [==============================] - 51s 47ms/step - loss: 3.7769 - acc: 0.0882 - val_loss: 13.8356 - val_acc: 0.0809\n",
            "Epoch 2/5\n",
            "1088/1088 [==============================] - 31s 28ms/step - loss: 3.3088 - acc: 0.1287 - val_loss: 12.9294 - val_acc: 0.0404\n",
            "Epoch 3/5\n",
            "1088/1088 [==============================] - 31s 28ms/step - loss: 3.0016 - acc: 0.1415 - val_loss: 3.5138 - val_acc: 0.1213\n",
            "Epoch 4/5\n",
            "1088/1088 [==============================] - 31s 28ms/step - loss: 2.9340 - acc: 0.1535 - val_loss: 3.0681 - val_acc: 0.1691\n",
            "Epoch 5/5\n",
            "1088/1088 [==============================] - 31s 28ms/step - loss: 2.8011 - acc: 0.1801 - val_loss: 4.2805 - val_acc: 0.0809\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f14dcde8898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "EHdv9srNMlSw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}